{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f55d84",
   "metadata": {
    "papermill": {
     "duration": 0.003096,
     "end_time": "2025-09-05T08:02:43.404163",
     "exception": false,
     "start_time": "2025-09-05T08:02:43.401067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9af91b2c",
   "metadata": {
    "papermill": {
     "duration": 0.002328,
     "end_time": "2025-09-05T08:02:43.409120",
     "exception": false,
     "start_time": "2025-09-05T08:02:43.406792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Bank Ensemble: V-Blend**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195b9d3",
   "metadata": {
    "papermill": {
     "duration": 0.002029,
     "end_time": "2025-09-05T08:02:43.413495",
     "exception": false,
     "start_time": "2025-09-05T08:02:43.411466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://www.kaggle.com/code/stpeteishii/bank-ensemble-h-blend\n",
    "\n",
    "https://www.kaggle.com/code/stpeteishii/bank-ensemble-v-blend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3214ac",
   "metadata": {
    "papermill": {
     "duration": 0.002013,
     "end_time": "2025-09-05T08:02:43.418078",
     "exception": false,
     "start_time": "2025-09-05T08:02:43.416065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://www.kaggle.com/code/nina2025/ps-s5e8-v-blend\n",
    "\n",
    "https://www.kaggle.com/code/nina2025/ps-s5e8-binary-classification-hv-blend-bokeh-copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b972b32",
   "metadata": {
    "papermill": {
     "duration": 0.002005,
     "end_time": "2025-09-05T08:02:43.422328",
     "exception": false,
     "start_time": "2025-09-05T08:02:43.420323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## **Blending Pipeline Overview**\n",
    "\n",
    "This pipeline implements an **adaptive weighted blending** method that dynamically adjusts weights based on prediction confidence intervals.\n",
    "\n",
    "### Pipeline Stages:\n",
    "\n",
    "1. **Data Ingestion**\n",
    "   - Load multiple submission files (CSV format)\n",
    "   - Each file contains predictions from different models\n",
    "   - Files are identified by their performance scores (e.g., 0.97772, 0.97771)\n",
    "\n",
    "2. **Data Merging**\n",
    "   - Combine all predictions into a single DataFrame\n",
    "   - Use a common ID column to align predictions\n",
    "   - Each model's predictions become separate columns\n",
    "\n",
    "3. **Confidence Assessment**\n",
    "   - Calculate `mx-m` (maximum minus minimum) for each row\n",
    "   - This represents the spread/disagreement between models\n",
    "   - Categorizes predictions into confidence tiers:\n",
    "     - **Tier 1**: High confidence (0.00 < mx-m ≤ 0.10)\n",
    "     - **Tier 2**: Medium confidence (0.10 < mx-m ≤ 0.20)  \n",
    "     - **Tier 3**: Low confidence (mx-m > 0.20)\n",
    "\n",
    "4. **Adaptive Weighting**\n",
    "   - **Base Weights**: Static weights assigned to each model\n",
    "   - **Position Weights**: Dynamic weights based on prediction ranking\n",
    "   - **Three Weight Sets**: Different weight combinations for each confidence tier\n",
    "\n",
    "5. **Blending Execution**\n",
    "   - **Descending Sort**: Rank predictions from highest to lowest\n",
    "   - **Ascending Sort**: Rank predictions from lowest to highest  \n",
    "   - **Final Blend**: 70% descending + 30% ascending blend\n",
    "\n",
    "### The Blending Method: Adaptive Position-Based Weighting\n",
    "\n",
    "**Core Concept**: The blend doesn't use fixed weights. Instead, it considers both the model's inherent quality AND its relative position in the prediction ranking for each specific sample.\n",
    "\n",
    "**Weight Components:**\n",
    "1. **Model Quality Weight**: Fixed weight reflecting overall model performance\n",
    "2. **Position Bonus/Penalty**: Adjustments based on where the model ranks for this specific prediction\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "```\n",
    "Final_Weight = Base_Weight + Position_Adjustment\n",
    "\n",
    "Final_Prediction = Σ (Model_Prediction × Final_Weight)\n",
    "```\n",
    "\n",
    "**Three Confidence-Based Strategies:**\n",
    "- **High Confidence**: Smaller adjustments, trust top-ranked models more\n",
    "- **Medium Confidence**: Moderate adjustments, balance between models  \n",
    "- **Low Confidence**: Larger adjustments, more conservative blending\n",
    "\n",
    "### Key Advantages:\n",
    "\n",
    "1. **Context-Aware**: Adapts to prediction uncertainty\n",
    "2. **Robust**: Handles cases where models strongly disagree\n",
    "3. **Performance-Tuned**: Different strategies for different confidence levels\n",
    "4. **Explainable**: You can see which models contributed most for each prediction\n",
    "\n",
    "### Parameter Structure:\n",
    "\n",
    "The method uses three weight sets:\n",
    "- `subwts`: Position adjustments for high confidence\n",
    "- `subwts2`: Position adjustments for medium confidence  \n",
    "- `subwts3`: Position adjustments for low confidence\n",
    "\n",
    "Each model has:\n",
    "- `name`: File identifier\n",
    "- `weight`: Base model quality weight\n",
    "\n",
    "### Output Features:\n",
    "\n",
    "1. **Detailed Analysis**: Shows predictions, confidence scores, and ranking\n",
    "2. **Visualization**: Position distribution charts for model rankings\n",
    "3. **Final Submission**: Blended predictions ready for competition submission\n",
    "\n",
    "This method is particularly effective for competitions where different models excel in different regions of the prediction space, providing a sophisticated way to leverage the strengths of each ensemble member.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447f112e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T08:02:43.428732Z",
     "iopub.status.busy": "2025-09-05T08:02:43.428418Z",
     "iopub.status.idle": "2025-09-05T08:03:15.645284Z",
     "shell.execute_reply": "2025-09-05T08:03:15.644121Z"
    },
    "papermill": {
     "duration": 32.223557,
     "end_time": "2025-09-05T08:03:15.648046",
     "exception": false,
     "start_time": "2025-09-05T08:02:43.424489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id   _   0.97772  0.97771  0.97770   _    mx-m   _   \\\n",
      "0  750000        0.0072   0.0048   0.0006      0.0066        \n",
      "1  750001        0.0765   0.0441   0.0120      0.0645        \n",
      "2  750002        0.0007   0.0005   0.0001      0.0006        \n",
      "3  750003        0.0006   0.0005   0.0001      0.0005        \n",
      "4  750004        0.0091   0.0056   0.0012      0.0079        \n",
      "\n",
      "                          alls   _   ensemble  \n",
      "0  [0.97772, 0.97771, 0.97770]         0.0069  \n",
      "1  [0.97772, 0.97771, 0.97770]         0.0727  \n",
      "2  [0.97772, 0.97771, 0.97770]         0.0007  \n",
      "3  [0.97772, 0.97771, 0.97770]         0.0006  \n",
      "4  [0.97772, 0.97771, 0.97770]         0.0087  \n",
      "       id   _   0.97772  0.97771  0.97770   _    mx-m   _   \\\n",
      "0  750000        0.0072   0.0048   0.0006      0.0066        \n",
      "1  750001        0.0765   0.0441   0.0120      0.0645        \n",
      "2  750002        0.0007   0.0005   0.0001      0.0006        \n",
      "3  750003        0.0006   0.0005   0.0001      0.0005        \n",
      "4  750004        0.0091   0.0056   0.0012      0.0079        \n",
      "\n",
      "                          alls   _   ensemble  \n",
      "0  [0.97770, 0.97771, 0.97772]         0.0066  \n",
      "1  [0.97770, 0.97771, 0.97772]         0.0701  \n",
      "2  [0.97770, 0.97771, 0.97772]         0.0007  \n",
      "3  [0.97770, 0.97771, 0.97772]         0.0006  \n",
      "4  [0.97770, 0.97771, 0.97772]         0.0084  \n",
      "       id       y\n",
      "0  750000 0.00681\n",
      "1  750001 0.07188\n",
      "2  750002 0.00071\n",
      "3  750003 0.00062\n",
      "4  750004 0.00860\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def v_blend(path_to_ds, file_short_names, dk):\n",
    "\n",
    "    def read(dk, i):\n",
    "        tnm = dk[\"subm\"][i][\"name\"]\n",
    "        FiN = dk[\"path\"] + tnm + \".csv\"\n",
    "        df = pd.read_csv(FiN)\n",
    "        # Handle column renaming more robustly\n",
    "        if 'target' in df.columns:\n",
    "            df = df.rename(columns={'target': tnm})\n",
    "        if dk[\"target\"] in df.columns and dk[\"target\"] != tnm:\n",
    "            df = df.rename(columns={dk[\"target\"]: tnm})\n",
    "        return df\n",
    "        \n",
    "    def merge(dfs_subm):\n",
    "        if not dfs_subm:\n",
    "            return pd.DataFrame()\n",
    "        df_subms = dfs_subm[0]\n",
    "        for i in range(1, len(dfs_subm)):\n",
    "            df_subms = pd.merge(df_subms, dfs_subm[i], on=[dk['id']])\n",
    "        return df_subms\n",
    "        \n",
    "    def da(dk, sorting_direction):\n",
    "        \n",
    "        dfs_subm = [read(dk, i) for i in range(len(dk[\"subm\"]))]\n",
    "        df_subms = merge(dfs_subm)\n",
    "        \n",
    "        if df_subms.empty:\n",
    "            print(\"No data found. Check file paths and names.\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        cols = [col for col in df_subms.columns if col != dk['id']]\n",
    "        short_name_cols = cols.copy()  # Use actual column names\n",
    "        \n",
    "        def alls(x, sd=sorting_direction, cs=cols):\n",
    "            reverse = True if sd == 'desc' else False\n",
    "            tes = {c: x[c] for c in cs}.items()\n",
    "            subms_sorted = [t[0] for t in sorted(tes, key=lambda k: k[1], reverse=reverse)]\n",
    "            return subms_sorted\n",
    "            \n",
    "        def summa(x, cs, wts, ic_alls): \n",
    "            return sum([x[cs[j]] * (wts[0][j] + wts[1][ic_alls[j]]) for j in range(len(cs))])\n",
    "            \n",
    "        wts = [\n",
    "            [[e['weight'] for e in dk[\"subm\"]], dk[\"subwts\"]],\n",
    "            [[e['weight'] for e in dk[\"subm2\"]], dk[\"subwts2\"]],\n",
    "            [[e['weight'] for e in dk[\"subm3\"]], dk[\"subwts3\"]],\n",
    "        ]\n",
    "        \n",
    "        def correct(x, cs=cols, wts=wts):\n",
    "            i = [x['alls'].index(c) for c in short_name_cols]\n",
    "            if 0.00 < x['mx-m'] <= 0.10: \n",
    "                return summa(x, cs, wts[0], i)\n",
    "            elif 0.10 < x['mx-m'] <= 0.20: \n",
    "                return summa(x, cs, wts[1], i)\n",
    "            else:                          \n",
    "                return summa(x, cs, wts[2], i)\n",
    "                \n",
    "        def amxm(x, cs=cols):\n",
    "            list_values = [x[c] for c in cs]\n",
    "            mxm = abs(max(list_values) - min(list_values))\n",
    "            return mxm\n",
    "            \n",
    "        df_subms['mx-m'] = df_subms.apply(lambda x: amxm(x), axis=1)\n",
    "        df_subms['alls'] = df_subms.apply(lambda x: alls(x), axis=1)\n",
    "        df_subms[dk[\"target\"]] = df_subms.apply(lambda x: correct(x), axis=1)\n",
    "        \n",
    "        # Rename columns for display\n",
    "        schema_rename = {old_nc: new_shnc for old_nc, new_shnc in zip(cols, short_name_cols)}\n",
    "        df_subms = df_subms.rename(columns=schema_rename)\n",
    "        df_subms = df_subms.rename(columns={dk[\"target\"]: \"ensemble\"})\n",
    "        \n",
    "        # Add separator column\n",
    "        df_subms.insert(loc=1, column=' _ ', value=['   '] * len(df_subms))\n",
    "        df_subms[' _ '] = df_subms[' _ '].astype(str)\n",
    "        \n",
    "        # Configure display options\n",
    "        pd.set_option('display.max_rows', 100)\n",
    "        pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "        \n",
    "        # Select and order columns for display\n",
    "        vcols = [dk['id']] + [' _ '] + short_name_cols + [' _ '] + ['mx-m'] + [' _ '] + ['alls'] + [' _ '] + ['ensemble']\n",
    "        df_subms = df_subms[vcols]\n",
    "        \n",
    "        # Display first 5 rows\n",
    "        print(df_subms.head(5))\n",
    "        \n",
    "        # Reset float format and prepare for export\n",
    "        pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "        df_subms = df_subms.rename(columns={\"ensemble\": dk[\"target\"]})\n",
    "        df_subms.to_csv(f'tida_{sorting_direction}.csv', index=False)\n",
    "        \n",
    "        return df_subms[[dk['id'], dk['target']]]\n",
    "   \n",
    "    def ensemble_da(dk): \n",
    "        dfD = da(dk, 'desc')\n",
    "        dfA = da(dk, 'asc')\n",
    "        \n",
    "        if dfD.empty or dfA.empty:\n",
    "            print(\"Error: One or both DataFrames are empty\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        # Combine desc and asc results\n",
    "        dfA[dk['target']] = (dk['desc'] * dfD[dk['target']] + \n",
    "                             dk['asc'] * dfA[dk['target']])\n",
    "        return dfA\n",
    "    \n",
    "    return ensemble_da(dk)\n",
    "\n",
    "\n",
    "def data_in_col(i, matrix):\n",
    "    return [row[i] for row in matrix]\n",
    "\n",
    "\n",
    "def info_mx_m(df):\n",
    "    if df.empty:\n",
    "        print(\"DataFrame is empty\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        matrix = [ast.literal_eval(row.alls) for row in df.itertuples()]\n",
    "        subms = sorted(matrix[0])\n",
    "        \n",
    "        df_subms = pd.DataFrame({f'col_{i}': data_in_col(i, matrix) for i in range(len(subms))})\n",
    "        \n",
    "        fig, axes = plt.subplots(ncols=len(subms), figsize=(12, 3))\n",
    "        if len(subms) == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for i in range(len(subms)):\n",
    "            sns.countplot(x=df_subms[f\"col_{i}\"], ax=axes[i])\n",
    "            axes[i].set_title(f'Position {i+1}')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in info_mx_m: {e}\")\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    path = '/kaggle/input/30-august-2025-ps-s5e8/' + 'submission '\n",
    "    fins = ['0.97772', '0.97771', '0.97770']\n",
    "\n",
    "    params_v16 = {\n",
    "        'path': path,\n",
    "        'id': 'id',\n",
    "        'target': \"y\",\n",
    "        'desc': 0.70,\n",
    "        'asc': 0.30,\n",
    "        'subwts': [+0.03, -0.02, -0.01],\n",
    "        'subm': [\n",
    "            {'name': fins[0], 'weight': 0.85},\n",
    "            {'name': fins[1], 'weight': 0.14},\n",
    "            {'name': fins[2], 'weight': 0.01},\n",
    "        ],\n",
    "        'subm2': [\n",
    "            {'name': fins[0], 'weight': 0.79},\n",
    "            {'name': fins[1], 'weight': 0.19},\n",
    "            {'name': fins[2], 'weight': 0.02},\n",
    "        ],\n",
    "        'subwts2': [+0.04, -0.01, -0.03],\n",
    "        'subm3': [\n",
    "            {'name': fins[0], 'weight': 0.85},\n",
    "            {'name': fins[1], 'weight': 0.14},\n",
    "            {'name': fins[2], 'weight': 0.01},\n",
    "        ],\n",
    "        'subwts3': [+0.03, -0.01, -0.02]\n",
    "    }\n",
    "\n",
    "    params = params_v16\n",
    "\n",
    "    df = v_blend(path, fins, params)\n",
    "\n",
    "    if not df.empty:\n",
    "        df.to_csv('submission.csv', index=False)\n",
    "        print(df.head())\n",
    "        \n",
    "        # Optional: Call info_mx_m if you want to analyze the results\n",
    "        # info_mx_m(df)\n",
    "    else:\n",
    "        print(\"No output generated. Check your input files and parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ec6e0",
   "metadata": {
    "papermill": {
     "duration": 0.002393,
     "end_time": "2025-09-05T08:03:15.653138",
     "exception": false,
     "start_time": "2025-09-05T08:03:15.650745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287cc58",
   "metadata": {
    "papermill": {
     "duration": 0.002331,
     "end_time": "2025-09-05T08:03:15.658009",
     "exception": false,
     "start_time": "2025-09-05T08:03:15.655678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here's a comparison table between **v_blend** (Vertical/Adaptive Blending) and **h_blend** (Horizontal/Static Blending):\n",
    "\n",
    "## Comparison Table: v_blend vs h_blend\n",
    "\n",
    "| Aspect | v_blend (Vertical/Adaptive Blending) | h_blend (Horizontal/Static Blending) |\n",
    "|--------|--------------------------------------|--------------------------------------|\n",
    "| **Core Approach** | Adaptive, sample-level weighting | Static, fixed weighting across all samples |\n",
    "| **Weight Application** | Dynamic weights per prediction based on confidence | Fixed weights for all predictions |\n",
    "| **Confidence Sensitivity** | ✅ Uses prediction spread (mx-m) to adjust weights | ❌ Ignores prediction confidence levels |\n",
    "| **Weight Components** | Base weight + position adjustment | Single fixed weight per model |\n",
    "| **Weight Sets** | Multiple sets (3 tiers for different confidence levels) | Single weight set |\n",
    "| **Sorting Direction** | Both ascending and descending blends combined | Typically single direction or no sorting |\n",
    "| **Complexity** | High - adaptive logic per sample | Low - simple weighted average |\n",
    "| **Computational Cost** | Higher due to per-sample calculations | Lower - simple arithmetic operations |\n",
    "| **Flexibility** | Adapts to different prediction scenarios | Rigid - same blending for all cases |\n",
    "| **Parameter Tuning** | Complex - multiple weight sets to optimize | Simple - fewer parameters to tune |\n",
    "| **Use Case** | When models have varying performance across data regions | When models perform consistently across dataset |\n",
    "| **Error Handling** | Better handles model disagreements | Can be skewed by outlier predictions |\n",
    "| **Implementation** | Requires ranking and confidence calculations | Simple weighted average formula |\n",
    "| **Output Analysis** | Provides detailed confidence metrics | Basic prediction output only |\n",
    "| **Visualization** | Includes ranking distribution charts | Limited or no visualization |\n",
    "| **Best For** | Competitions with diverse prediction patterns | Stable, well-behaved model ensembles |\n",
    "\n",
    "---\n",
    "\n",
    "## Performance Scenarios\n",
    "\n",
    "| Scenario | v_blend Performance | h_blend Performance |\n",
    "|----------|---------------------|---------------------|\n",
    "| **Models agree strongly** | ⭐⭐⭐⭐⭐ (Optimal weighting) | ⭐⭐⭐⭐⭐ (Works well) |\n",
    "| **Models disagree moderately** | ⭐⭐⭐⭐⭐ (Adapts weights) | ⭐⭐ (Static weights may fail) |\n",
    "| **Models disagree strongly** | ⭐⭐⭐⭐ (Conservative blending) | ⭐ (Poor performance) |\n",
    "| **Mixed confidence levels** | ⭐⭐⭐⭐⭐ (Handles variety) | ⭐⭐ (One-size-fits-all fails) |\n",
    "| **Simple ensemble** | ⭐⭐⭐ (Overkill) | ⭐⭐⭐⭐⭐ (Perfect fit) |\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Each\n",
    "\n",
    "### Choose v_blend when:\n",
    "- ✅ Models have specialized strengths in different data regions\n",
    "- ✅ Prediction confidence varies significantly across samples\n",
    "- ✅ You need robust handling of model disagreements\n",
    "- ✅ Competition performance demands sophisticated blending\n",
    "- ✅ You have time for parameter optimization\n",
    "\n",
    "### Choose h_blend when:\n",
    "- ✅ Models perform consistently across all data\n",
    "- ✅ You need a simple, fast solution\n",
    "- ✅ Model predictions are generally aligned\n",
    "- ✅ You're working with well-correlated models\n",
    "- ✅ Quick implementation is priority\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Considerations\n",
    "\n",
    "**v_blend Advantages:**\n",
    "- Better handling of edge cases\n",
    "- More explainable results (you see which models \"win\" per sample)\n",
    "- Higher potential peak performance\n",
    "\n",
    "**v_blend Disadvantages:**\n",
    "- More complex to implement and debug\n",
    "- Higher risk of overfitting to validation set\n",
    "- Requires more careful parameter tuning\n",
    "\n",
    "**h_blend Advantages:**\n",
    "- Simple to implement and maintain\n",
    "- Less prone to overfitting\n",
    "- Faster computation\n",
    "- Easier to explain to others\n",
    "\n",
    "**h_blend Disadvantages:**\n",
    "- Can't adapt to varying prediction scenarios\n",
    "- May underutilize model specialties\n",
    "- Limited performance ceiling\n",
    "\n",
    "The choice depends on your specific competition context, model characteristics, and available optimization time."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12937777,
     "sourceId": 91719,
     "sourceType": "competition"
    },
    {
     "datasetId": 8168613,
     "sourceId": 12910306,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38.788604,
   "end_time": "2025-09-05T08:03:16.381395",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T08:02:37.592791",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
